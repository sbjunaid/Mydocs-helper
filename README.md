# ğŸ§  MyDocs Assistant (Offline & Free - LLaMA3)

A powerful **offline knowledge assistant** built using **LangChain**, **Ollama (LLaMA3)**, and **Streamlit**. This assistant reads your `.txt` documents and answers questions using local embeddings + local language models â€” no internet or API keys needed!

> âœ¨ Developed by **Sayed Bakhtiar Junaid**

---

## ğŸš€ Features

- ğŸ” Ask questions about your own `.txt` documents (postmortems, logs, infra notes, etc.)
- ğŸ§  Local embeddings using `all-MiniLM-L6-v2`
- ğŸ’¬ Powered by **Gemma 3** via Ollama (fully offline)
- ğŸ“ Supports multiple text files (placed in `docs/` folder)
- âš¡ Built with **LangChain** + **Streamlit**
- âŒ No OpenAI / Hugging Face API needed
- âœ… Works 100% locally â€“ no internet required after setup

---

## ğŸ“‚ Folder Structure

assignment/
â”‚
â”œâ”€â”€ app.py # Streamlit main app
â”œâ”€â”€ docs/ # Place your .txt knowledge base files here
â”‚ â”œâ”€â”€ github1.txt
â”‚ â”œâ”€â”€ debugginglog.txt
â”‚ â””â”€â”€ ...
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md # You're here!


---

## âš™ï¸ Setup Instructions

### 1. Create and activate virtual environment

```bash
python -m venv venv
venv\Scripts\activate    # Windows
# source venv/bin/activate  # Mac/Linux
```
### 2.Install Python dependencies
```bash
pip install -r requirements.txt
```
### 3. Install Ollama and Gemma 3 model
(Download Ollama â†’ Install it â†’ Then pull the model):
```bash
ollama run gemma:2b  # Or use llama3, mistral, etc. if you prefer
```
### 4.â–¶ï¸ Run the App
```bash
streamlit run app.py
```
## ğŸ™‹â€â™‚ï¸ Developer
Made with ğŸ’», ğŸ˜¤, and â˜• by Sayed Bakhtiar Junaid
